{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmPZBCJUUiEt",
        "outputId": "6f20bf17-16c6-4e5d-8506-bd0cb993b044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import sparse\n",
        "import ast\n",
        "class CF(object):\n",
        "    \"\"\"docstring for CF\"\"\"\n",
        "    def __init__(self, Y_data, k, dist_func = cosine_similarity, uuCF = 1):\n",
        "        self.uuCF = uuCF # user-user (1) or item-item (0) CF\n",
        "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]\n",
        "        self.k = k\n",
        "        self.dist_func = dist_func # đánh giá độ tương quan giữ 2 user\n",
        "        self.Ybar_data = None # bản sao của ydata dùng để lưu ma trận nornalize\n",
        "        # number of users and items. Remember to add 1 since id starts from 0\n",
        "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1 # số lượng User\n",
        "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1 # số lượng Item\n",
        "    def add(self, new_data):\n",
        "        \"\"\"\n",
        "        Update Y_data matrix when new ratings come.\n",
        "        For simplicity, suppose that there is no new user or item.\n",
        "        \"\"\"\n",
        "        self.Y_data = np.concatenate((self.Y_data, new_data), axis = 0)\n",
        "\n",
        "    def normalize_Y(self):\n",
        "        users = self.Y_data[:, 0] # all users - first col of the Y_data\n",
        "        self.Ybar_data = self.Y_data.copy()\n",
        "        self.mu = np.zeros((self.n_users,)) # lư\n",
        "\n",
        "        for n in range(self.n_users):\n",
        "            # row indices of rating done by user n\n",
        "            # since indices need to be integers, we need to convert\n",
        "            ids = np.where(users == n)[0].astype(np.int32)\n",
        "            # indices of all ratings associated with user n\n",
        "            item_ids = self.Y_data[ids, 1]\n",
        "            # and the corresponding ratings\n",
        "            ratings = self.Y_data[ids, 2]\n",
        "            # take mean\n",
        "            m = np.mean(ratings)\n",
        "            if np.isnan(m):\n",
        "                m = 0 # to avoid empty array and nan value\n",
        "            self.mu[n] = m\n",
        "            # normalize\n",
        "            self.Ybar_data[ids, 2] = ratings - self.mu[n] + 0.01\n",
        "        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
        "            (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
        "\n",
        "        self.Ybar = self.Ybar.tocsr()\n",
        "\n",
        "    def similarity(self):\n",
        "        eps = 1e-6\n",
        "        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)\n",
        "\n",
        "    def refresh(self):\n",
        "        \"\"\"\n",
        "        Normalize data and calculate similarity matrix again (after\n",
        "        some few ratings added)\n",
        "        \"\"\"\n",
        "        print('Y_data: ',self.Y_data)\n",
        "        self.normalize_Y()\n",
        "        self.similarity()\n",
        "\n",
        "\n",
        "    def fit(self):\n",
        "        self.refresh()\n",
        "\n",
        "\n",
        "    def __pred(self, u, i, normalized = 1):\n",
        "        \"\"\"\n",
        "        predict the rating of user u for item i (normalized)\n",
        "        if you need the un\n",
        "        \"\"\"\n",
        "        # Step 1: find all users who rated i\n",
        "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32) # vi tri user danh gia item\n",
        "        # Step 2:\n",
        "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
        "        # Step 3: find similarity btw the current user and others\n",
        "        # who already rated i\n",
        "\n",
        "        if len(users_rated_i) != 0:\n",
        "          sim = self.S[u, users_rated_i] # matran similarity\n",
        "          sim = sim + 0.01\n",
        "          # Step 4: find the k most similarity users\n",
        "          a = np.argsort(sim)[-self.k:]\n",
        "          c = users_rated_i[a]\n",
        "          # and the corresponding similarity levels\n",
        "          nearest_s = sim[a]\n",
        "          #print('users_rated_i[a]',users_rated_i[a])\n",
        "          # How did each of 'near' users rated item i\n",
        "          r = self.Ybar[i, users_rated_i[a]]\n",
        "          if normalized:\n",
        "              # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
        "              Z = (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
        "              return Z,c\n",
        "          return Z,c\n",
        "        else:\n",
        "          return 0,0\n",
        "\n",
        "    def pred(self, u, i, normalized = 1):\n",
        "        \"\"\"\n",
        "        predict the rating of user u for item i (normalized)\n",
        "        if you need the un\n",
        "        \"\"\"\n",
        "        if self.uuCF: return self.__pred(u, i, normalized)\n",
        "        return self.__pred(i, u, normalized)\n",
        "\n",
        "\n",
        "    def recommend(self, u):\n",
        "        \"\"\"\n",
        "        Determine all items should be recommended for user u.\n",
        "        The decision is made based on all i such that:\n",
        "        self.pred(u, i) > 0. Suppose we are considering items which\n",
        "        have not been rated by u yet.\n",
        "        \"\"\"\n",
        "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
        "        items_rated_by_u = self.Y_data[ids, 1].tolist()\n",
        "        recommended_items = []\n",
        "        for i in range(self.n_items):\n",
        "            if i not in items_rated_by_u:\n",
        "                rating,c = self.__pred(u, i)\n",
        "                if rating > 0:\n",
        "                    recommended_items.append([rating,i,c])\n",
        "        sorted_list = sorted(recommended_items, reverse=True)\n",
        "        four_lines = sorted_list[:20]\n",
        "        arr1 = []\n",
        "        arr2 = []\n",
        "        for i in four_lines:\n",
        "          arr1.append(i[1])\n",
        "          arr2.append(i[2])\n",
        "        #four_lines_last_column = [row[-1] for row in four_lines]\n",
        "        return arr1,arr2\n",
        "\n"
      ],
      "metadata": {
        "id": "d_lVFXODUnR6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ratings_base = pd.read_csv('/content/gdrive/MyDrive/ratings.csv')\n",
        "df_book = pd.read_csv('/content/gdrive/MyDrive/prepared_data_book.csv')"
      ],
      "metadata": {
        "id": "ioDHKCPdUo8R"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_base = ratings_base[['user_id', 'book_id', 'rating']]"
      ],
      "metadata": {
        "id": "ublDoD4uUs-g"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted = ratings_base.sort_values(by='user_id')"
      ],
      "metadata": {
        "id": "KR2ItH-5U4QE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_sorted[0:2226]"
      ],
      "metadata": {
        "id": "Ts49UvhzVMVa"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_id = df_train['book_id'].unique()"
      ],
      "metadata": {
        "id": "9Bk8mqh8WOPc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['user_id'].unique().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmPjkXbtexc4",
        "outputId": "ee0ac28e-5210-4fac-d06b-10a1fee34de2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(173,)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_book[\"product_id\"] = books_id"
      ],
      "metadata": {
        "id": "IWJCsQ_nB0mz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = 'prepared_data_book.csv'\n",
        "df_book.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "LvFMBsC3FINK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_rating = 'comments.csv'\n",
        "df_train.to_csv(output_file_rating, index=False)"
      ],
      "metadata": {
        "id": "TUMk-W4QFuOX"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rate_train = df_train.values"
      ],
      "metadata": {
        "id": "gwyaDYEzUvG1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rs = CF(rate_train, k =3, uuCF = 1)\n",
        "rs.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vEHVhTFUwo5",
        "outputId": "550fa2e3-5351-4cd6-f7e9-e1d45b20369e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_data:  [[   1 1180    4]\n",
            " [   1 4893    3]\n",
            " [   1 6285    4]\n",
            " ...\n",
            " [ 173  437    3]\n",
            " [ 173  745    1]\n",
            " [ 173  268    3]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u=2\n",
        "movie_id_rcm,user_id_same = rs.recommend(u)"
      ],
      "metadata": {
        "id": "c-kk84xfUzFh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(rs,open('model.pkl','wb'))"
      ],
      "metadata": {
        "id": "k1URZyEZbo5g"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open('model.pkl','rb'))\n",
        "print(model.recommend(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfeaYnXubtOn",
        "outputId": "7b1503f5-5e0e-41cd-9089-69c8f26739ac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([8627, 6944, 8946, 8615, 7771, 3921, 9997, 9966, 9946, 9927, 9909, 9908, 9886, 9882, 9862, 9826, 9783, 9773, 9671, 9664], [array([72], dtype=int32), array([49], dtype=int32), array([ 16, 131, 155], dtype=int32), array([87, 87], dtype=int32), array([ 90, 145], dtype=int32), array([158, 158], dtype=int32), array([52], dtype=int32), array([89], dtype=int32), array([126], dtype=int32), array([105], dtype=int32), array([23], dtype=int32), array([29], dtype=int32), array([153], dtype=int32), array([23], dtype=int32), array([89], dtype=int32), array([96], dtype=int32), array([92], dtype=int32), array([60], dtype=int32), array([60], dtype=int32), array([25], dtype=int32)])\n"
          ]
        }
      ]
    }
  ]
}